{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de1c5c8",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6fd66",
   "metadata": {},
   "source": [
    "## Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c1d77e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ec0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269cfe0e",
   "metadata": {},
   "source": [
    "`training_data` and `test_data` are `Dataset`s. We will pass them as an argument to DataLoader to wrap an iterable over them, which supports batshing, sampling, etc.\n",
    "\n",
    "The batch size of 64 indicates that each element in the dataloader iterable will return a batch of 64 features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32bc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a09a0",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a671b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a4e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fc775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy arrays\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3943ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor: tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "Random tensor: tensor([[0.2474, 0.5688],\n",
      "        [0.7430, 0.8446]])\n"
     ]
    }
   ],
   "source": [
    "# new tensor tries to retain the properties (shape, datatype)\n",
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones tensor: {x_ones}\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
    "print(f\"Random tensor: {x_rand}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24704cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor: \n",
      "tensor([[0.5403, 0.0700, 0.9369],\n",
      "        [0.7965, 0.3235, 0.9711]]) \n",
      "\n",
      "Ones tensor: \n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeroes tensor: \n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shapes\n",
    "shape = (2, 3, )\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros_like(ones_tensor)\n",
    "\n",
    "print(f'Random tensor: \\n{rand_tensor} \\n')\n",
    "\n",
    "print(f'Ones tensor: \\n{ones_tensor} \\n')\n",
    "\n",
    "print(f'Zeroes tensor: \\n{zeros_tensor} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0ff5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4])\n",
      "Datatype: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Atributes of a tensor\n",
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape: {tensor.shape}\")\n",
    "print(f\"Datatype: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "218ffea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations on Tensors\n",
    "\n",
    "# Moving to the current accelerator (GPU)\n",
    "\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a543859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[:, -1]}\")\n",
    "tensor[:, 1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1aba401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5997f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "\n",
    "# Element wise product\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(z1)\n",
    "print(torch.mul(tensor, tensor, out=z3))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7984b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "# Converting a single element tensor to numerical value:\n",
    "\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6378ba66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# Inplace operations\n",
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5a8416f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Bridging with numpy\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddb4b1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Change in the tensor reflects in the numpy array\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88ad4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array to ToTensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d4cd6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([4., 4., 4., 4., 4.], dtype=torch.float64), n: [4. 4. 4. 4. 4.]\n",
      "t: tensor([5., 5., 5., 5., 5.], dtype=torch.float64), n: [5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "source": [
    "# Changes in the numpy reflect in the tensor\n",
    "\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}, n: {n}\")\n",
    "\n",
    "t.add_(1)\n",
    "print(f\"t: {t}, n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c539bf6",
   "metadata": {},
   "source": [
    "# Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2c116e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f90ce09",
   "metadata": {},
   "source": [
    "We can index `Datasets` manually like a list: `training_data[index]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "834ab24e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    # This litterally just generates a random index to select from training_data\n",
    "    sample_idx = torch.randint(len(training_data), size=(1, )).item()\n",
    "    img, label = training_data[int(sample_idx)]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acedf6",
   "metadata": {},
   "source": [
    "## Custom Datasets\n",
    "\n",
    "We can create custom dataset classes using the `Dataset` class as template .\n",
    "\n",
    "This class must contain the functions `__init__`, `__len__`, `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1e1c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import decode_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae1148",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "We now use DataLoatder that wraps a Dataset, and allows us to perform operations more easily on the dataset (the operations we will be doing when training the model).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30bb6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4821ee2e",
   "metadata": {},
   "source": [
    "Each iteration will now return a batch from the datasets, containing batch_size features and labels. `shuffle=True` indicates that after iterating over all the batches the data will be shuffled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff575093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 6\n"
     ]
    }
   ],
   "source": [
    "# Diplay image and label\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291fbfc",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "To manipulate the data and make it suitable for training, we use transforms. \n",
    "\n",
    "All TorchVision datasets have two parameters: `transform` to modify the features and `target_transform` to modify the labels. Both parameters accept callables containing the transformation logic.\n",
    "\n",
    "`torchvision.transforms` contains several commonly used transforms.\n",
    "\n",
    "For example, in FashionMNIST, the features are images and labels integers. For training, we need the features as normalized tensors and labels as one-hot encoded tensors. Hence, we use `ToTensor` and `Lambda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4be291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a653f3",
   "metadata": {},
   "source": [
    "## ToTensor()\n",
    "\n",
    "converts a PIL image or Numpy `ndarray` into a `FloatTensor`. This scales the image's pixel intensity values in the range [0., 1.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4348b78",
   "metadata": {},
   "source": [
    "## Lambda Transforms\n",
    "\n",
    "Lambda transforms apply any user-defined lambda function.\n",
    "\n",
    "In the example we first created a tensor with 10 zeroes and then assign 1 t the index given by the label `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6da5df1",
   "metadata": {},
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "The torch.nn namespace provides all the building blocks needed for a neural network.\n",
    "\n",
    "Every module in PyTorch subclasses the nn.Module.\n",
    "\n",
    "A neural network is a module itself that consists of other modules (layers).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ffd3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af61d32c",
   "metadata": {},
   "source": [
    "## Getting the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f13e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ee566",
   "metadata": {},
   "source": [
    "## Define the Class\n",
    "\n",
    "We define our neural network by subclassing nn.Module, and initialize the neural network layers in `__init__`. Every `nn.Module` subclass implements the operations on input data in the forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee5c1a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bbc2c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45be46",
   "metadata": {},
   "source": [
    "To use the model, we pass the input data. This executes the model's `forward`, along with some background operations. Do not call the model.forward() directly.\n",
    "\n",
    "Calling the model on the input will return a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the nn.Softmax module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca1a8f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([8], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099dface",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1203,  0.0075,  0.0139, -0.0420, -0.1418, -0.0259, -0.0228, -0.0143,\n",
      "          0.0154, -0.0210]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e751fe0",
   "metadata": {},
   "source": [
    "## Model Layers\n",
    "\n",
    "Let's see what happens with three images when passing them through the network:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c36d6163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a995b",
   "metadata": {},
   "source": [
    "### `nn.Flatten`\n",
    "\n",
    "converts each 2D 28x28 image into a continuous array of 748 pixel values. (We keep the 3 images separated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5896ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc703c",
   "metadata": {},
   "source": [
    "### `nn.Linear`\n",
    "\n",
    "Applies a linear transformation on the input using stored weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58a53443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b273c9",
   "metadata": {},
   "source": [
    "### `nn.ReLU`\n",
    "\n",
    "Nonlinear activation funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ab114a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1354,  0.3903, -0.1990, -0.5939,  0.3034, -0.0578, -0.3310, -0.4349,\n",
      "         -0.2656,  0.0240, -0.5093,  0.0452,  0.3862,  0.2466, -0.1258,  0.2202,\n",
      "         -0.7655, -0.0663, -0.1467, -0.4217],\n",
      "        [-0.0235,  0.3388, -0.2124, -0.3354,  0.3975,  0.0523,  0.3553, -0.5615,\n",
      "         -0.5226,  0.2287, -0.1790, -0.0193,  0.2792,  0.2793, -0.2970,  0.1684,\n",
      "         -0.5589,  0.0626,  0.1217, -0.6101],\n",
      "        [-0.2548,  0.0123, -0.3578, -0.4062,  0.1763,  0.1773,  0.0678, -0.6828,\n",
      "         -0.2761, -0.1194, -0.0467, -0.1823,  0.1348,  0.3847, -0.0240,  0.2472,\n",
      "         -0.2314, -0.1027, -0.0114, -0.3717]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0000, 0.3903, 0.0000, 0.0000, 0.3034, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0240, 0.0000, 0.0452, 0.3862, 0.2466, 0.0000, 0.2202, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.3388, 0.0000, 0.0000, 0.3975, 0.0523, 0.3553, 0.0000, 0.0000,\n",
      "         0.2287, 0.0000, 0.0000, 0.2792, 0.2793, 0.0000, 0.1684, 0.0000, 0.0626,\n",
      "         0.1217, 0.0000],\n",
      "        [0.0000, 0.0123, 0.0000, 0.0000, 0.1763, 0.1773, 0.0678, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1348, 0.3847, 0.0000, 0.2472, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e7865",
   "metadata": {},
   "source": [
    "### `nn.Sequential`\n",
    "\n",
    "is an ordered container of modules. The data is passed through all the modules in the same order as defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90f1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9015e8",
   "metadata": {},
   "source": [
    "### `nn.Softmax`\n",
    "\n",
    "Softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dae4b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1027, 0.1142, 0.1255, 0.1255, 0.0945, 0.0940, 0.0889, 0.0727, 0.0910,\n",
      "         0.0910],\n",
      "        [0.1183, 0.1188, 0.1149, 0.1296, 0.0842, 0.0911, 0.0807, 0.0668, 0.0934,\n",
      "         0.1022],\n",
      "        [0.1103, 0.1137, 0.1178, 0.1253, 0.0929, 0.0931, 0.0843, 0.0694, 0.0959,\n",
      "         0.0972]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6027891",
   "metadata": {},
   "source": [
    "## Model paramenters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aac9f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[ 0.0046,  0.0111,  0.0124,  ...,  0.0007,  0.0137,  0.0350],\n",
      "        [ 0.0029, -0.0074,  0.0131,  ...,  0.0306, -0.0220, -0.0004]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0034, -0.0277], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[ 0.0289,  0.0245,  0.0077,  ...,  0.0166,  0.0137,  0.0187],\n",
      "        [-0.0069,  0.0190, -0.0310,  ...,  0.0420, -0.0351,  0.0309]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0367,  0.0440], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[ 0.0076, -0.0179, -0.0283,  ..., -0.0185,  0.0238, -0.0149],\n",
      "        [-0.0063,  0.0230, -0.0361,  ...,  0.0345, -0.0063, -0.0268]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([-0.0434,  0.0420], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We wil iterate over each parameter now, print its size and preview its values\n",
    "\n",
    "print(f\"Model structure: {model} \\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c97fad0",
   "metadata": {},
   "source": [
    "# Automatic Differentiation with `torch.autograd`\n",
    "\n",
    "`torch.autograd` automatically computes the gradient for any computational graph (useful at backpropagation).\n",
    "\n",
    "For instance, a one-layer neural network, input `x`, parameters `w`, `b` and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "103101d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3408, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(5)\n",
    "y = torch.zeros(3) # expected output\n",
    "w = torch.randn(5, 3, requires_grad = True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5e460",
   "metadata": {},
   "source": [
    "within this computational graph, since we will need the gradient of the loos function with respect to variables w and b, we use `requires_grad=True` to specify that we need these gradients to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95276e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x70dc564d8f10>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x70dc564d8df0>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963dea6c",
   "metadata": {},
   "source": [
    "## Computing gradients\n",
    "\n",
    "To optimize the weights, we need the **Gradients with respect to the parameters for a fixed input**. To compute this, we just call `loss.backward()` and retrieve the parameter gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3d9b311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0154, 0.0966, 0.3245],\n",
      "        [0.0154, 0.0966, 0.3245],\n",
      "        [0.0154, 0.0966, 0.3245],\n",
      "        [0.0154, 0.0966, 0.3245],\n",
      "        [0.0154, 0.0966, 0.3245]])\n",
      "tensor([0.0154, 0.0966, 0.3245])\n"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d9296e",
   "metadata": {},
   "source": [
    "## Disabling Gradient Tracking\n",
    "\n",
    "If we, for example, have finished training, and will only do forward computations for now on, we can stop tracking computations by surronding the computation code with torch.no_grad() block:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c603cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c56b3526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# other method\n",
    "\n",
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c77e5b",
   "metadata": {},
   "source": [
    "# Optimizing the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d61f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"data\",\n",
    "    train = False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2bfb487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ae594",
   "metadata": {},
   "source": [
    "## Epochs\n",
    "Each iteration of the optimization loop is called an epoch.\n",
    "Each epoch consists of two parts:\n",
    "\n",
    "- **Train Loop**: iterate over the training dataset and try to converge to optimal parameters.\n",
    "- **Validation loop**: iterate over the test dataset to check if model performance is improving\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f11150a",
   "metadata": {},
   "source": [
    "## loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79befaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db2aad",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Optimization algorithms define how the process of adjusting model parameters is performed. All the logic is encapsulated in the optimizer object.\n",
    "\n",
    "There are many different optimizers available, that work better for different kinds of models and data.\n",
    "\n",
    "We initialize the optimizer by registering the model's parameters that need to be trained, and passing the learning rate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6e07c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c918f88",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "- Call `optimizer.zero_grad()` to reset the gradients of model parameters. (Gradiens by default add up)\n",
    "- Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss with respect to each parameter.\n",
    "- Then, we call `optimizer.step()` to adjust the parameters by the gradients collected.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86ce5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full implementation\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model for training model. Important for batch normalization\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropatation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss}, [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensuring that gradients are not computed\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8efb975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      " ---------------------\n",
      "loss: 2.1597931385040283, [   64/60000]\n",
      "loss: 2.152308940887451, [ 6464/60000]\n",
      "loss: 2.0905792713165283, [12864/60000]\n",
      "loss: 2.11921763420105, [19264/60000]\n",
      "loss: 2.057128429412842, [25664/60000]\n",
      "loss: 2.004812240600586, [32064/60000]\n",
      "loss: 2.0367531776428223, [38464/60000]\n",
      "loss: 1.948514699935913, [44864/60000]\n",
      "loss: 1.9529054164886475, [51264/60000]\n",
      "loss: 1.9030466079711914, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.6%, Avg loss: 1.886654 \n",
      "\n",
      "Epoch 2\n",
      " ---------------------\n",
      "loss: 1.9066790342330933, [   64/60000]\n",
      "loss: 1.8851983547210693, [ 6464/60000]\n",
      "loss: 1.7575665712356567, [12864/60000]\n",
      "loss: 1.8256242275238037, [19264/60000]\n",
      "loss: 1.6985121965408325, [25664/60000]\n",
      "loss: 1.6510663032531738, [32064/60000]\n",
      "loss: 1.6915966272354126, [38464/60000]\n",
      "loss: 1.5775587558746338, [44864/60000]\n",
      "loss: 1.6119581460952759, [51264/60000]\n",
      "loss: 1.5234339237213135, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.0%, Avg loss: 1.527733 \n",
      "\n",
      "Epoch 3\n",
      " ---------------------\n",
      "loss: 1.5835034847259521, [   64/60000]\n",
      "loss: 1.5597858428955078, [ 6464/60000]\n",
      "loss: 1.398343563079834, [12864/60000]\n",
      "loss: 1.492855429649353, [19264/60000]\n",
      "loss: 1.3640358448028564, [25664/60000]\n",
      "loss: 1.3575726747512817, [32064/60000]\n",
      "loss: 1.378103494644165, [38464/60000]\n",
      "loss: 1.2964380979537964, [44864/60000]\n",
      "loss: 1.3377971649169922, [51264/60000]\n",
      "loss: 1.2415995597839355, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.8%, Avg loss: 1.267132 \n",
      "\n",
      "Epoch 4\n",
      " ---------------------\n",
      "loss: 1.339933156967163, [   64/60000]\n",
      "loss: 1.3277578353881836, [ 6464/60000]\n",
      "loss: 1.1543591022491455, [12864/60000]\n",
      "loss: 1.273425579071045, [19264/60000]\n",
      "loss: 1.1440551280975342, [25664/60000]\n",
      "loss: 1.1688616275787354, [32064/60000]\n",
      "loss: 1.1864365339279175, [38464/60000]\n",
      "loss: 1.121641755104065, [44864/60000]\n",
      "loss: 1.1649081707000732, [51264/60000]\n",
      "loss: 1.0818595886230469, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.104759 \n",
      "\n",
      "Epoch 5\n",
      " ---------------------\n",
      "loss: 1.1748871803283691, [   64/60000]\n",
      "loss: 1.179857611656189, [ 6464/60000]\n",
      "loss: 0.9909225106239319, [12864/60000]\n",
      "loss: 1.1370964050292969, [19264/60000]\n",
      "loss: 1.0026859045028687, [25664/60000]\n",
      "loss: 1.0393437147140503, [32064/60000]\n",
      "loss: 1.0683925151824951, [38464/60000]\n",
      "loss: 1.0088149309158325, [44864/60000]\n",
      "loss: 1.050233006477356, [51264/60000]\n",
      "loss: 0.9827833771705627, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 0.998235 \n",
      "\n",
      "Epoch 6\n",
      " ---------------------\n",
      "loss: 1.057367205619812, [   64/60000]\n",
      "loss: 1.0827076435089111, [ 6464/60000]\n",
      "loss: 0.8767977356910706, [12864/60000]\n",
      "loss: 1.04481041431427, [19264/60000]\n",
      "loss: 0.9101805686950684, [25664/60000]\n",
      "loss: 0.9453734755516052, [32064/60000]\n",
      "loss: 0.9896331429481506, [38464/60000]\n",
      "loss: 0.9340530633926392, [44864/60000]\n",
      "loss: 0.9693165421485901, [51264/60000]\n",
      "loss: 0.915732741355896, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.8%, Avg loss: 0.924063 \n",
      "\n",
      "Epoch 7\n",
      " ---------------------\n",
      "loss: 0.9691495895385742, [   64/60000]\n",
      "loss: 1.0140697956085205, [ 6464/60000]\n",
      "loss: 0.7937021851539612, [12864/60000]\n",
      "loss: 0.9782538414001465, [19264/60000]\n",
      "loss: 0.846547544002533, [25664/60000]\n",
      "loss: 0.8744267225265503, [32064/60000]\n",
      "loss: 0.9326165914535522, [38464/60000]\n",
      "loss: 0.8831683993339539, [44864/60000]\n",
      "loss: 0.9096522331237793, [51264/60000]\n",
      "loss: 0.8667112588882446, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.8%, Avg loss: 0.869564 \n",
      "\n",
      "Epoch 8\n",
      " ---------------------\n",
      "loss: 0.8996961116790771, [   64/60000]\n",
      "loss: 0.9618500471115112, [ 6464/60000]\n",
      "loss: 0.7306528687477112, [12864/60000]\n",
      "loss: 0.927870512008667, [19264/60000]\n",
      "loss: 0.8005968928337097, [25664/60000]\n",
      "loss: 0.8196302652359009, [32064/60000]\n",
      "loss: 0.888486385345459, [38464/60000]\n",
      "loss: 0.8473189473152161, [44864/60000]\n",
      "loss: 0.8645682334899902, [51264/60000]\n",
      "loss: 0.8286395072937012, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 69.0%, Avg loss: 0.827750 \n",
      "\n",
      "Epoch 9\n",
      " ---------------------\n",
      "loss: 0.8435822129249573, [   64/60000]\n",
      "loss: 0.9194619059562683, [ 6464/60000]\n",
      "loss: 0.6814020276069641, [12864/60000]\n",
      "loss: 0.8884232044219971, [19264/60000]\n",
      "loss: 0.7656817436218262, [25664/60000]\n",
      "loss: 0.7769191265106201, [32064/60000]\n",
      "loss: 0.8524524569511414, [38464/60000]\n",
      "loss: 0.8211698532104492, [44864/60000]\n",
      "loss: 0.8296588659286499, [51264/60000]\n",
      "loss: 0.7976295351982117, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.794566 \n",
      "\n",
      "Epoch 10\n",
      " ---------------------\n",
      "loss: 0.7972449660301208, [   64/60000]\n",
      "loss: 0.8834881782531738, [ 6464/60000]\n",
      "loss: 0.6418862342834473, [12864/60000]\n",
      "loss: 0.8569035530090332, [19264/60000]\n",
      "loss: 0.7381234765052795, [25664/60000]\n",
      "loss: 0.7431755065917969, [32064/60000]\n",
      "loss: 0.8217525482177734, [38464/60000]\n",
      "loss: 0.8010495901107788, [44864/60000]\n",
      "loss: 0.8015588521957397, [51264/60000]\n",
      "loss: 0.7713978290557861, [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 71.8%, Avg loss: 0.767203 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n ---------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91373d5d",
   "metadata": {},
   "source": [
    "# Saving and loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4885a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308eeba",
   "metadata": {},
   "source": [
    "Models store the learned parameters in an internal state dictionary called `state_dict`. These can be persisted using the torch.save method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3beedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542ff18",
   "metadata": {},
   "source": [
    "To load model weights, we create an instance of the same model first, and then load the parameters using `load_state_dict()` method.\n",
    "\n",
    "`weights_only=True` is just a best practice when loading weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c07fbac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.vgg16() # Untrained model (we didn't especified weights)\n",
    "\n",
    "model.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d393c99",
   "metadata": {},
   "source": [
    "## Saving and Loading Models with Shapes\n",
    "\n",
    "We might want to save the structure of the class (the network structure) along with the parameters, in which case we can pass `model` instead of `model.state_dict()` to the saving function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a9c6d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55cab3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pth', weights_only=False) # I honestly didn't understand why weights_only=False here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c5dff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
