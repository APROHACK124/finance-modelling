{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2b8340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB_PATH_DEFAULT] /home/aprohack/Desktop/all_folders/Investings_project/app/data/stock_data.db\n",
      "{'foreign_keys': 1, 'journal_mode': 'wal', 'synchronous': 1}\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "import sys\n",
    "import os\n",
    "PROJECT_ROOT = os.path.abspath('../..')\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# AJUSTA ESTOS IMPORTS a tu proyecto real:\n",
    "from machine_learning.data_collectors import build_ml_dataframe, build_supervised_dataset\n",
    "from machine_learning.evaluators import eval_regression_extended\n",
    "\n",
    "from machine_learning.tcn.train_tcn import train_eval_tcn, TrainTCNConfig\n",
    "from machine_learning.artifacts import load_model_artifact_auto\n",
    "\n",
    "from machine_learning.data_collectors import (\n",
    "    build_ml_dataframe,\n",
    "    build_supervised_dataset,\n",
    "    time_split_masks,\n",
    "    purged_ts_cv_splits,\n",
    "    TARGET_HORIZONS,\n",
    "    TARGET_LOOKBACKS,\n",
    "    parse_feat_lag\n",
    ")\n",
    "from database_tier1 import TARGET_STOCKS\n",
    "from python_scripts.LLM_analysis.preprocess_store_database import get_connection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d11397d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lb=120, h=20\n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar datos (long: symbol, timestamp, OHLCV, indicadores, etc.)\n",
    "conn = get_connection()\n",
    "\n",
    "timeframe = \"1Day\"\n",
    "symbols = TARGET_STOCKS\n",
    "\n",
    "start = None\n",
    "end = None\n",
    "\n",
    "include_indicators = False\n",
    "indicator_names = []\n",
    "# indicator_names = ['RSI_14', 'BBB_20_2.0', 'BBP_20_2.0', 'ATRr_14']\n",
    "\n",
    "include_economic_indicators = False\n",
    "econ_indicator_names = []\n",
    "# econ_indicator_names = ['CPI', 'UNEMPLOYMENT']\n",
    "\n",
    "include_fmp = False\n",
    "fmp_feature_names = []\n",
    "keep_fmp_asof_date = False\n",
    "fmp_prefix = 'fmp'\n",
    "\n",
    "# -----------------------\n",
    "# ELIGE LOOKBACK AQUÍ\n",
    "# -----------------------\n",
    "lookback = TARGET_LOOKBACKS[2]  # <-- cámbialo\n",
    "\n",
    "# 3 horizontes baseline (puedes editar)\n",
    "#horizons = [5, 20, 60]\n",
    "horizon = TARGET_HORIZONS[2]\n",
    "\n",
    "base_feature_cols = ['open', 'high', 'low', 'close', 'volume', 'trade_count']\n",
    "\n",
    "lags_by_feature = None\n",
    "default_lags = lookback\n",
    "\n",
    "\n",
    "feature_cols = base_feature_cols + indicator_names + econ_indicator_names + fmp_feature_names\n",
    "\n",
    "\n",
    "print(f\"lb={lookback}, h={horizon}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec35e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = build_ml_dataframe(\n",
    "    conn,\n",
    "    symbols=symbols,\n",
    "    timeframe=\"1Day\",\n",
    "    start=\"2015-01-01\",\n",
    "    end=\"2025-12-31\",\n",
    "    include_indicators=True,\n",
    "    include_econ=True,\n",
    "    include_fmp=False,\n",
    ")\n",
    "\n",
    "# 2) Definir feature_cols (excluir columnas no-feature)\n",
    "non_feature_cols = {\"symbol\", \"timestamp\", \"timeframe\"}\n",
    "feature_cols = [c for c in df.columns if c not in non_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457abf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single-horizon check: (198102, 420) (198102,) Index(['symbol', 'timestamp', 'target_timestamp'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aprohack/Desktop/all_folders/Investings_project/app/investenv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 001] train_loss=0.008085 | val_rmse_mean=0.090712 (h5:0.040973, h20:0.079231, h60:0.151932) | best=0.090712 @epoch 1 | no_improve=0\n",
      "[epoch 002] train_loss=0.006621 | val_rmse_mean=0.092036 (h5:0.042118, h20:0.080064, h60:0.153926) | best=0.090712 @epoch 1 | no_improve=1\n",
      "[epoch 003] train_loss=0.006577 | val_rmse_mean=0.090218 (h5:0.040991, h20:0.079035, h60:0.150630) | best=0.090218 @epoch 3 | no_improve=0\n",
      "[epoch 004] train_loss=0.006526 | val_rmse_mean=0.089591 (h5:0.039675, h20:0.077803, h60:0.151295) | best=0.089591 @epoch 4 | no_improve=0\n",
      "[epoch 005] train_loss=0.006480 | val_rmse_mean=0.091655 (h5:0.041064, h20:0.077576, h60:0.156324) | best=0.089591 @epoch 4 | no_improve=1\n",
      "[epoch 006] train_loss=0.006448 | val_rmse_mean=0.091345 (h5:0.039652, h20:0.081338, h60:0.153045) | best=0.089591 @epoch 4 | no_improve=2\n",
      "[epoch 007] train_loss=0.006407 | val_rmse_mean=0.092037 (h5:0.042899, h20:0.078584, h60:0.154628) | best=0.089591 @epoch 4 | no_improve=3\n",
      "[epoch 008] train_loss=0.006329 | val_rmse_mean=0.095196 (h5:0.046404, h20:0.082612, h60:0.156572) | best=0.089591 @epoch 4 | no_improve=4\n",
      "[epoch 009] train_loss=0.006284 | val_rmse_mean=0.089169 (h5:0.041292, h20:0.076893, h60:0.149323) | best=0.089169 @epoch 9 | no_improve=0\n",
      "[epoch 010] train_loss=0.006250 | val_rmse_mean=0.090810 (h5:0.041445, h20:0.077288, h60:0.153696) | best=0.089169 @epoch 9 | no_improve=1\n",
      "[epoch 011] train_loss=0.006167 | val_rmse_mean=0.093605 (h5:0.043400, h20:0.081835, h60:0.155581) | best=0.089169 @epoch 9 | no_improve=2\n",
      "[epoch 012] train_loss=0.006103 | val_rmse_mean=0.089810 (h5:0.040417, h20:0.077137, h60:0.151876) | best=0.089169 @epoch 9 | no_improve=3\n",
      "[epoch 013] train_loss=0.006094 | val_rmse_mean=0.093533 (h5:0.039353, h20:0.079102, h60:0.162142) | best=0.089169 @epoch 9 | no_improve=4\n",
      "[epoch 014] train_loss=0.006038 | val_rmse_mean=0.092387 (h5:0.039164, h20:0.080838, h60:0.157160) | best=0.089169 @epoch 9 | no_improve=5\n",
      "[epoch 015] train_loss=0.006017 | val_rmse_mean=0.099397 (h5:0.041154, h20:0.085843, h60:0.171192) | best=0.089169 @epoch 9 | no_improve=6\n",
      "[epoch 016] train_loss=0.006015 | val_rmse_mean=0.091879 (h5:0.039445, h20:0.080060, h60:0.156130) | best=0.089169 @epoch 9 | no_improve=7\n",
      "[epoch 017] train_loss=0.005921 | val_rmse_mean=0.092980 (h5:0.039703, h20:0.080339, h60:0.158898) | best=0.089169 @epoch 9 | no_improve=8\n",
      "[epoch 018] train_loss=0.005905 | val_rmse_mean=0.093327 (h5:0.039074, h20:0.084115, h60:0.156793) | best=0.089169 @epoch 9 | no_improve=9\n",
      "[epoch 019] train_loss=0.005901 | val_rmse_mean=0.093289 (h5:0.039476, h20:0.078621, h60:0.161771) | best=0.089169 @epoch 9 | no_improve=10\n",
      "Early stopping: no improvement for 10 epochs.\n",
      "\n",
      "=== VALIDACIÓN (best epoch) ===\n",
      "H5: RMSE=0.041292 | MAE=0.027636 | R2=-0.1834 | IC=-0.0107 | RankIC=-0.0236 | DailyIC*=-0.0075 | DailyRankIC*=-0.0200 | QuantileSpread*=-0.003094\n",
      "H20: RMSE=0.076893 | MAE=0.054360 | R2=-0.0269 | IC=0.0805 | RankIC=0.0621 | DailyIC*=0.0715 | DailyRankIC*=0.0587 | QuantileSpread*=0.018743\n",
      "H60: RMSE=0.149323 | MAE=0.096920 | R2=-0.0467 | IC=0.0848 | RankIC=0.0935 | DailyIC*=0.0933 | DailyRankIC*=0.0848 | QuantileSpread*=0.034210\n",
      "(* = se busca por substring; depende del schema exacto de eval_regression_extended)\n",
      "\n",
      "\n",
      "=== TEST (best epoch) ===\n",
      "H5: RMSE=0.083817 | MAE=0.035061 | R2=-0.0934 | IC=-0.0094 | RankIC=-0.0060 | DailyIC*=-0.0120 | DailyRankIC*=0.0056 | QuantileSpread*=0.003370\n",
      "H20: RMSE=0.160913 | MAE=0.068017 | R2=-0.0287 | IC=-0.0106 | RankIC=0.0141 | DailyIC*=-0.0011 | DailyRankIC*=0.0303 | QuantileSpread*=-0.003944\n",
      "H60: RMSE=0.287339 | MAE=0.131695 | R2=-0.0731 | IC=-0.0469 | RankIC=0.0485 | DailyIC*=-0.0179 | DailyRankIC*=0.0562 | QuantileSpread*=-0.053694\n",
      "(* = se busca por substring; depende del schema exacto de eval_regression_extended)\n",
      "\n",
      "Artifact guardado en: runs/tcn_20260121_180550\n",
      "Horizons: [5, 20, 60]\n",
      "Keys metrics: dict_keys(['val', 'test', 'conformal', 'best_val_rmse_mean', 'best_epoch'])\n",
      "Loaded model_type: tcn_regressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aprohack/Desktop/all_folders/Investings_project/app/investenv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "# (Opcional) sanity-check single-horizon dataset (verifica meta['target_timestamp'])\n",
    "X_wide_5, y_5, meta_5 = build_supervised_dataset(\n",
    "    df,\n",
    "    feature_cols=feature_cols,\n",
    "    lookback=60,\n",
    "    horizon=5,\n",
    "    price_col=\"close\",\n",
    "    group_col=\"symbol\",\n",
    "    timestamp_col=\"timestamp\",\n",
    ")\n",
    "print(\"Single-horizon check:\", X_wide_5.shape, y_5.shape, meta_5.columns)\n",
    "\n",
    "# 3) Entrenar + evaluar + guardar artifact (multi-horizon en el mismo modelo)\n",
    "cfg = TrainTCNConfig(\n",
    "    lookback=60,\n",
    "    horizons=(5, 20, 60),\n",
    "    batch_size=256,\n",
    "    dropout=0.10,\n",
    "    channels=(64, 64, 64, 64),\n",
    "    kernel_size=3,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=50,\n",
    "    patience=10,\n",
    "    grad_clip=1.0,\n",
    "    periods_per_year=252,   # diario\n",
    "    run_base_dir=\"runs\",\n",
    "    run_name=None,\n",
    ")\n",
    "\n",
    "out = train_eval_tcn(\n",
    "    df,\n",
    "    feature_cols=feature_cols,\n",
    "    build_supervised_dataset_fn=build_supervised_dataset,\n",
    "    eval_fn=eval_regression_extended,\n",
    "    cfg=cfg,\n",
    ")\n",
    "\n",
    "print(\"Artifact guardado en:\", out[\"run_dir\"])\n",
    "print(\"Horizons:\", out[\"horizons\"])\n",
    "print(\"Keys metrics:\", out[\"metrics\"].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c965d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_type: tcn_regressor\n"
     ]
    }
   ],
   "source": [
    "# 4) Cargar artifact (auto)\n",
    "artifact = load_model_artifact_auto(out[\"run_dir\"], map_location=\"cpu\")\n",
    "model = artifact[\"model\"]\n",
    "scaler = artifact[\"scaler\"]\n",
    "config = artifact[\"config\"]\n",
    "print(\"Loaded model_type:\", config.get(\"model_type\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "investenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
