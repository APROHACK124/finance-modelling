{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6af72dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DB_PATH_DEFAULT] /workspace/finance-modelling/data/stock_data.db\n",
      "{'foreign_keys': 1, 'journal_mode': 'wal', 'synchronous': 1}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "PROJECT_ROOT = os.path.abspath('../..')\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# AJUSTA ESTOS IMPORTS a tu proyecto real:\n",
    "from machine_learning.data_collectors import build_ml_dataframe, build_supervised_dataset\n",
    "from machine_learning.evaluators import eval_regression_extended\n",
    "\n",
    "from machine_learning.tcn.train_tcn import train_eval_tcn, TrainTCNConfig\n",
    "from machine_learning.artifacts import load_model_artifact_auto\n",
    "\n",
    "from machine_learning.data_collectors import (\n",
    "    build_ml_dataframe,\n",
    "    build_supervised_dataset,\n",
    "    time_split_masks,\n",
    "    purged_ts_cv_splits,\n",
    "    TARGET_HORIZONS,\n",
    "    TARGET_LOOKBACKS,\n",
    "    parse_feat_lag\n",
    ")\n",
    "from database_tier1 import TARGET_STOCKS\n",
    "from python_scripts.LLM_analysis.preprocess_store_database import get_connection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from train_walk_forward_tcn import run_walk_forward_tcn, ExperimentConfig\n",
    "from walk_forward import WalkForwardConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd344ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lb=252, h=20\n"
     ]
    }
   ],
   "source": [
    "# 1) Cargar datos (long: symbol, timestamp, OHLCV, indicadores, etc.)\n",
    "conn = get_connection()\n",
    "\n",
    "timeframe = \"1Day\"\n",
    "symbols = TARGET_STOCKS\n",
    "\n",
    "start = None\n",
    "end = None\n",
    "\n",
    "include_indicators = False\n",
    "indicator_names = []\n",
    "# indicator_names = ['RSI_14', 'BBB_20_2.0', 'BBP_20_2.0', 'ATRr_14']\n",
    "\n",
    "include_economic_indicators = False\n",
    "econ_indicator_names = []\n",
    "# econ_indicator_names = ['CPI', 'UNEMPLOYMENT']\n",
    "\n",
    "include_fmp = False\n",
    "fmp_feature_names = []\n",
    "keep_fmp_asof_date = False\n",
    "fmp_prefix = 'fmp'\n",
    "\n",
    "# -----------------------\n",
    "# ELIGE LOOKBACK AQUÍ\n",
    "# -----------------------\n",
    "lookback = TARGET_LOOKBACKS[3]  # <-- cámbialo\n",
    "\n",
    "# 3 horizontes baseline (puedes editar)\n",
    "#horizons = [5, 20, 60]\n",
    "horizon = TARGET_HORIZONS[2]\n",
    "\n",
    "base_feature_cols = ['open', 'high', 'low', 'close', 'volume', 'trade_count']\n",
    "\n",
    "lags_by_feature = None\n",
    "default_lags = lookback\n",
    "\n",
    "\n",
    "feature_cols = base_feature_cols + indicator_names + econ_indicator_names + fmp_feature_names\n",
    "\n",
    "\n",
    "print(f\"lb={lookback}, h={horizon}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883282a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check horizon=5: (198102, 420) (198102,) Index(['symbol', 'timestamp', 'target_timestamp'], dtype='str')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = build_ml_dataframe(\n",
    "    conn,\n",
    "    symbols=symbols,\n",
    "    timeframe=\"1Day\",\n",
    "    start=\"2015-01-01\",\n",
    "    end=\"2025-12-31\",\n",
    "    include_indicators=True,\n",
    "    include_econ=True,\n",
    "    include_fmp=False,\n",
    ")\n",
    "\n",
    "# 2) feature_cols (excluir no-features)\n",
    "non_feature_cols = {\"symbol\", \"timestamp\", \"timeframe\"}\n",
    "feature_cols = [c for c in df.columns if c not in non_feature_cols]\n",
    "\n",
    "# 3) Sanity check explícito: build_supervised_dataset clásico (horizon=5, lags_by_feature=None)\n",
    "X_wide_5, y_5, meta_5 = build_supervised_dataset(\n",
    "    df,\n",
    "    feature_cols=feature_cols,\n",
    "    lookback=60,\n",
    "    horizon=5,\n",
    "    price_col=\"close\",\n",
    "    group_col=\"symbol\",\n",
    "    timestamp_col=\"timestamp\",\n",
    "    lags_by_feature=None,   # explícito, como pediste\n",
    ")\n",
    "print(\"Sanity check horizon=5:\", X_wide_5.shape, y_5.shape, meta_5.columns)\n",
    "assert \"target_timestamp\" in meta_5.columns, \"meta debe incluir target_timestamp\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d949285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparam selection (val mean DailyIC promedio en folds) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/finance-modelling/.venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (Opcional) selección simple de hiperparámetros (ejemplo: probar ic_lambda)\u001b[39;00m\n\u001b[32m     21\u001b[39m hp_candidates = [\n\u001b[32m     22\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mloss_hp\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mic_lambda\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.0\u001b[39m}},   \u001b[38;5;66;03m# solo SmoothL1\u001b[39;00m\n\u001b[32m     23\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mloss_hp\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mic_lambda\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.2\u001b[39m}},   \u001b[38;5;66;03m# SmoothL1 + IC loss\u001b[39;00m\n\u001b[32m     24\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m out = \u001b[43mrun_walk_forward_tcn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_supervised_dataset_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuild_supervised_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_regression_extended\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhp_candidates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhp_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mrun_dir:\u001b[39m\u001b[33m\"\u001b[39m, out[\u001b[33m\"\u001b[39m\u001b[33mrun_dir\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfinal verify diffs:\u001b[39m\u001b[33m\"\u001b[39m, out[\u001b[33m\"\u001b[39m\u001b[33mfinal\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mverify\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/machine_learning/tcn/train_walk_forward_tcn.py:889\u001b[39m, in \u001b[36mrun_walk_forward_tcn\u001b[39m\u001b[34m(df, feature_cols, build_supervised_dataset_fn, eval_fn, cfg, hp_candidates)\u001b[39m\n\u001b[32m    887\u001b[39m tmp_dir = folds_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m_hpsearch_tmp_fold\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf.fold\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_cand\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mci\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    888\u001b[39m tmp_dir.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m res = \u001b[43mtrain_single_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeta_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhorizons\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhorizons_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_each_fold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# no verificar en búsqueda\u001b[39;49;00m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfold_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m fold_scores.append(\u001b[38;5;28mfloat\u001b[39m(res[\u001b[33m\"\u001b[39m\u001b[33mbest_val_mean_daily_ic\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m    902\u001b[39m \u001b[38;5;66;03m# Limpieza best-effort (no es crítica; puedes comentar si quieres inspeccionar)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/machine_learning/tcn/train_walk_forward_tcn.py:362\u001b[39m, in \u001b[36mtrain_single_fold\u001b[39m\u001b[34m(fold, fold_dir, X_all, y_all, meta_all, feature_cols, horizons, eval_fn, cfg, fold_seed)\u001b[39m\n\u001b[32m    359\u001b[39m batch_sampler.set_epoch(epoch)\n\u001b[32m    361\u001b[39m losses = []\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:741\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    739\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    744\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    745\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    746\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    747\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:803\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    801\u001b[39m data = \u001b[38;5;28mself\u001b[39m._dataset_fetcher.fetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    802\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m--> \u001b[39m\u001b[32m803\u001b[39m     data = \u001b[43m_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pin_memory_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py:92\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     90\u001b[39m     clone = copy.copy(data)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data):\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m         clone[i] = \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m clone\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)([pin_memory(sample, device) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data])  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/finance-modelling/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/pin_memory.py:57\u001b[39m, in \u001b[36mpin_memory\u001b[39m\u001b[34m(data, device)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpin_memory\u001b[39m(data, device=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch.Tensor):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[32m     59\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Walk-forward + TCN\n",
    "cfg = ExperimentConfig(\n",
    "    lookback=TARGET_LOOKBACKS[3],\n",
    "    horizons=(5, 20, 60),\n",
    "    wf=WalkForwardConfig(\n",
    "        target_col=\"target_timestamp\",\n",
    "        train_span=252*5,   # rolling 5 años (en target timestamps)\n",
    "        val_span=126,       # 6m\n",
    "        test_span=126,      # 6m\n",
    "        step_span=126,      # reentreno semestral\n",
    "        embargo_span=0,\n",
    "        min_train_span=252*3,\n",
    "    ),\n",
    "    seed=0,\n",
    "    run_base_dir=\"../runs\",\n",
    "    run_name=None,\n",
    "    device=\"cuda\",\n",
    "    train_hp=TrainHP(num_workers=8, pin_memory=True)\n",
    ")\n",
    "\n",
    "# (Opcional) selección simple de hiperparámetros (ejemplo: probar ic_lambda)\n",
    "hp_candidates = [\n",
    "    {\"loss_hp\": {\"ic_lambda\": 0.0}},   # solo SmoothL1\n",
    "    {\"loss_hp\": {\"ic_lambda\": 0.2}},   # SmoothL1 + IC loss\n",
    "]\n",
    "\n",
    "out = run_walk_forward_tcn(\n",
    "    df,\n",
    "    feature_cols=feature_cols,\n",
    "    build_supervised_dataset_fn=build_supervised_dataset,\n",
    "    eval_fn=eval_regression_extended,\n",
    "    cfg=cfg,\n",
    "    hp_candidates=hp_candidates,\n",
    ")\n",
    "\n",
    "print(\"run_dir:\", out[\"run_dir\"])\n",
    "print(\"final verify diffs:\", out[\"final\"][\"verify\"])\n",
    "print(\"tabla folds:\\n\", out[\"agg_table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a30d7ae-bd3c-435e-8cc0-f42653d0f556",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tcn)",
   "language": "python",
   "name": "tcn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
